Comparison summary FTTransformer vs SparseFTTransformer (seed=42)
-------------------------------------------------------------
FT-Transformer (rtdl):
- n_parameters: 893179
- best_val_loss: 0.2603 (epoch 20)
- test_loss: 0.2664
- train_time_s: 567.94
- notes: attention maps collected (ranks printed in log)

SparseFTTransformer (sparse_ftt_plus):
- n_parameters: 893563
- best_val_loss: 0.2647 (epoch 20)
- test_loss: 0.2656
- train_time_s: 354.70
- feature_importance saved:
  - C:\Users\vleon\OneDrive\Documents\customers chuns\Customer churn-ft_transformer\results\feature_importance.npy
  - C:\Users\vleon\OneDrive\Documents\customers chuns\Customer churn-ft_transformer\results\feature_ranks.npy
  - C:\Users\vleon\OneDrive\Documents\customers chuns\Customer churn-ft_transformer\results\feature_importance_and_ranks.csv

Observations:
- Nombre de paramètres très proches.
- SparseFTTransformer a été ~213.24s plus rapide (567.94s vs 354.70s).
- Test loss légèrement meilleur pour SparseFTTransformer (0.2656 vs 0.2664), mais FT-Transformer a atteint un meilleur Val Loss (0.2603 vs 0.2647).
- Prochaine étape recommandée: réintroduire l'attention interprétable (V partagé + sparsemax), puis lancer des runs courts (1 epoch) pour valider intégration avant comparaisons longues.

Generated automatically from logs/logs (seed=42).